<!DOCTYPE html>
<!-- saved from url=(0063)http://twitter.github.io/bootstrap/examples/justified-nav.html# -->
<html lang="en">

<head>
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-60795702-1', 'auto');
        ga('send', 'pageview');

    </script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Welcome to Reda Bouadjenek's Home page</title>

    <!-- Bootstrap core CSS -->
    <link href="dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="justified-nav.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <script src="assets/js/ie-emulation-modes-warning.js"></script>

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="assets/js/ie10-viewport-bug-workaround.js"></script>

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <link rel='shortcut icon' href='img/favicon.ico' type='image/x-icon' />
</head>

<body>
    <div class="container">
        <div class="masthead">
            <div class="row">
                <div class="col-sm-9">
                    <h2 class="muted">Dr. Mohamed Reda Bouadjenek</h2>
                    <h4>BSc., MSc., and Ph.D. in Computer Science</h4>
                    <h4>Senior Lecturer, Applied Artificial Intelligence</h4>
                    <h5>Deputy course director of Master of Applied Artificial Intelligence</h5>          
                    <h5>Academic Director Innovation</h5>


                </div>
                <div class="col-sm-3">
                    <div style="text-align:center">
                        <img src="img/deakin2.png" height="90" alt="Deakin logo" />
                    </div>
                </div>
                <!--div class="col-sm-3">
                    <div style="text-align:center">
                        <img src="img/melbourne-university.jpg" height="90" alt="UniMelb logo" />
                    </div>
                </div-->
            </div>

            <!--h5>Hello. Hola. Aloha. Bonjour. مرحبا. Haai. Grüßgott. Goedendag. Oi. Shalom. Guten Tag. Ciào. Malo e lelei. Hei. 안녕. Yo.</h5-->

            <ul class="nav nav-justified">
                <li><a href="index.html">Home</a></li>
                <li><a href="CV-En-long-V1.pdf">CV</a></li>
                <!--li><a href="cv-long.pdf">CV Fr</a></li-->
                <li class="active"><a href="research.html">Research</a></li>
                <li><a href="grants-awards.html">Grants & Awards</a></li>   
                <li><a href="publications.html">Publications</a></li>
                <li><a href="teaching.html">Teaching</a></li>
               <li><a href="https://rbouadjenek.github.io/deakin-ai-challenge2023/">AI Challenge 2023</a></li>
            </ul>


            <!-- /.navbar -->
        </div>


        <!-- Jumbotron -->
        <div class="" style="text-align:justify;">
            
            <div class="row">
                <div class="col-sm-12">
            <h3 class="text-center">Research Overview: From Data to Decision-making for Better Services</h3>
                </div>
            </div>
            
            
            
            
            <h3 class="likesectionHead"><a id="x1-1000"></a>Introduction</h3>
<!--l. 31--><p class="noindent" >With the emergence of the social Web in the mid-2000s, the Web has evolved from a static Web, where users were only able to consume information, to a Web where users are also able to interact and produce information. This
evolution which is commonly known as Social Web or Web 2.0, has introduced new freedoms for the user in his
relation with the Web by facilitating his interactions with other users who have similar tastes or share similar
resources. Examples of Web 2.0 include social platforms and networks (such as MySpace, Facebook, and
LinkedIn), collaborative tagging sites (like delicious, CiteULike, and Flickr), microblogging sites (like Twitter and
Yammer), and even crowdsourced databases (e.g., Bioinformatics sequence databases such as GenBank or
UniProt).
<!--l. 44--><p class="noindent" >These platforms are commonly used as means to communicate with other users, exchange messages, share
resources (photos, videos, or bioinformatics sequences), comment, tag, maintain profiles, interact and
play online games, etc. In addition to dedicated social platforms, traditional content providers like
newspapers, tend to be more social since they provide to users means for sharing, commenting, and linking
documents together, e.g., sharing. These collaborative tasks are among the most important factors
for the increasingly quantity of available social data. Hence, the need to exploit this unprecedented
quantity of data is critical for many companies and their business. This has led to the development of
Data-driven Decision-making techniques to extract valuable knowledge from this data, based on
fast, effective and scalable data analysis and machine learning algorithms, which are at the heart of
my research interests focusing on descriptive, predictive, and prescriptive analytics of large-scale
data.
<!--l. 60--><p class="noindent" >Specifically, my research addresses data and information quality in crowdsourced databases, as well as the crucial
problem of enabling users to consume relevant information with respect to their interests and needs. This
task is commonly realized through content recommendation (such as movie Netflix, books on Kobo
or products on Amazon) or Information Retrieval ( on platforms like Google or Bing). However,
conventional models of recommendation and Information Retrieval don&#8217;t consider this side social
information, and proposing novel extensions are also at the heart of my work. As two exemplars of my
research:
                                                                                                
                                                                                                
     <ul class="itemize1">
     <li class="itemize">In Social Information Retrieval <span class="cite">[<a 
href="papers/IS-D-14-351.pdf">1</a>]</span>, I have extended conventional Information Retrieval models in
     order to incorporate side social information. Specifically, I have introduced a novel ranking function
     <span class="cite">[<a href="papers/sp086-bouadjenek.pdf">2</a>]</span>, a new Information Retrieval modeling schema <span class="cite">[<a 
href="papers/sp085-bouadjenek.pdf">3</a>,&#x00A0;<a 
href="papers/INS-D-15-2480.pdf">4</a>]</span>, and a query expansion algorithm <span class="cite">[<a href="papers/p1113-bouadjenek.pdf">5</a>,&#x00A0;<a 
href="papers/TLDKS-12008.pdf">6</a>]</span> all
     based on innovative social features. These contributions have been integrated into a social web search
     engine called LAICOS <span class="cite">[<a 
href="papers/demo16-bouadjenek.pdf">7</a>]</span>, which represented some of my major contributions to the area of Social
     Information Retrieval.
     </li>
     <li class="itemize">In data quality for collaborative bioinformatics databases (e.g., <span class="cite">[<a 
href="papers/bax021.pdf">8</a>,&#x00A0;<a 
href="papers/JBI-17-134.pdf">9</a>,&#x00A0;<a 
href="papers/sp0228-bouadjenek.pdf">10</a>,&#x00A0;<a 
href="papers/BINF-D-18-00977.pdf">11</a>]</span>), I have addressed the
     problem of identifying low-quality and suspicious records based on literature analysis. These databases
     contain  hundreds  of  millions  of  records  derived  from  submissions  by  individual  laboratories,  as
     well as from bulk submissions from large-scale sequencing centers. Their diversity and scale means
     that they suffer from a range of data quality issues including errors, discrepancies, redundancies,
     ambiguities, and incompleteness. In that context, I have combined a set of information retrieval and
     machine learning techniques while using the published literature as a background knowledge to detect
     literature-inconsistent records.</li></ul>
<!--l. 92--><p class="noindent" >With the increasing level of business competitiveness, investigating more intelligent and faster ways of analyzing,
exploring, using, and mining the data is a key aspect for many businesses. Hence, my objective is to go deep in the
development and the usage of data analytics in different areas from both academic and industry perspectives. To
elaborate in more detail, following is a summary of my ongoing research that enables this large-scale data processing for information retrieval and recommendation.
<!--l. 100--><p class="noindent" >
<h3 class="likesectionHead"><a 
 id="x1-2000"></a>Mining Massive Media</h3>
<!--l. 102--><p class="noindent" >Social media sites such as Twitter present a double-edged sword for users. On one hand these sources
contain a vast amount of novel and topical content that challenge traditional news media sources
in terms of their timeliness and diversity. Yet on the other hand they also contain a vast amount
of chatter and otherwise low-value content for most users&#8217; information needs where filtering out
irrelevant content is extremely time-consuming. My previous work on twitter topic classification <span class="cite">[<a 
href="papers/ICWSM2017.pdf">12</a>]</span>
has noted this need for topic-based filtering and has adopted a range of variations on supervised
classification techniques to build effective topic filters. However, there remain many fundamental
research questions that need to be answered on a longitudinal study of the performance of such
supervised topic classifiers. For example, can we identify temporally unstable features? How can we
design a learning algorithm that automatically downweights the influence of temporally unstable
features?
<!--l. 118--><p class="noindent" >
<h3 class="likesectionHead"><a 
 id="x1-3000"></a>Visualizing large-scale Data for Information Retrieval</h3>
<!--l. 120--><p class="noindent" >In many applications that involve searching geo-temporal data, results are often displayed on a map or other
interactive visual interfaces. However, in many settings of interactive visual search, it is time-consuming to
individually examine all matching results. This suggests the need to aggregate results, for example, via an
                                                                                                
                                                                                                
unsupervised clustering method like K-means. These ideas build on the <span 
class="cmti-10x-x-109">&#8220;cluster hypothesis&#8221; </span>of information
retrieval, which posits that documents in the same cluster are likely to address similar relevance needs for the
search task. Unfortunately, the use of unsupervised methods does not necessarily guarantee that the
clusters themselves are relevant. Therefore, it is critical to develop relevance-driven clustering methods
for Visual Information Displays (VIDs) that are capable of displaying highly relevant clusters for
queries.
<!--l. 134--><p class="noindent" >Since &#8220;retrieved&#8221; information elements are not individually selected, but rather clustered using the relevance
signal of each element, the problem is clearly an optimization problem of how to restrict cluster settings to show
the user the most relevant information to his query. While this notably diverges from the standard information
retrieval setting where ranked documents are chosen individually, these additional constraints do not change the
overall objective to select relevant information given the user&#8217;s information need as represented by
the given relevance measure. In this work, I intend to provide a unified framework that abstracts
presentation-specific details of different information clusters for VIDs and facilitates an optimization perspective
of clustering w.r.t. a provided relevance measure. I also intend to define a new specific objective
function for optimization that is suitable for this visualization task. Finally, I aim to propose new, fast,
effective and scalable algorithms that optimize the objective function that I define for this visualization
task.
<!--l. 170--><p class="noindent" >
<h3 class="likesectionHead"><a 
 id="x1-4000"></a>Machine Learning and Social Media Analysis for Financial Analytics</h3>
<!--l. 172--><p class="noindent" >Social media platforms such as Twitter or StockTwits are widely used for sharing advice between investors,
traders, and entrepreneurs. The popularity of these platforms, the vast amount of information generated by active
members, and their usage by influential people imply that this social media content is often predictive of financial
markets.
<!--l. 179--><p class="noindent" >In this project, I plan to develop novel algorithms to model the influence of social media on stock
market performance. These novel methods are based on machine learning principles that will provide
financial analysts with powerful tools for summarizing social media sentiment and opinion regarding
individual stocks as well as providing quantitative predictions for use in investment and trading
decisions.
<!--l. 186--><p class="noindent" >Specifically, the research questions I intend to answer in this project are: how can we model and capture the
influence of users, brand and industry mentions over time? How can we deal with varying reliability of users for
different stocks, or users with non-stationary (i.e., fluctuating) influence over time? How can we automatically
identify brands that may be relevant to a stock ticker to reduce the number of features in our prediction models
and improve the quality of fit (i.e., it is easier to learn accurate parameters in smaller models since it is harder to
overfit in these cases)?
<!--l. 196--><p class="noindent" >
<h3 class="likesectionHead"><a 
 id="x1-5000"></a>Future Research Directions </h3>
<!--l. 198--><p class="noindent" >While my work has made contributions to large-scale data processing and retrieval, there still remains a vast
amount of research to improve data processing, retrieval and recommendation technologies in an online
                                                                                                
                                                                                                
framework. To this end, following are a few key areas where my future research will help close the loop between
data and decisions:
     <ol  class="enumerate1" >
     <li class="enumerate" id="x1-5002x1"><b>Combining diverse side information for recommendation and IR: </b>users are interacting on
     diverse online services such as social network platforms, collaborative tagging sites, microblogging
     sites,  and  online  game  platforms.  These  services  provide  valuable  information  to  enhance
     recommendation  and  IR.  A  critical  question  is  how  to  extend  existing  solutions  into  a  unified
     framework that considers multiple and diverse data sources? I have attempted to answer this question
     for recommendation using a co-matrix factorization approach of multiple data sources <span class="cite">[<a 
href="papers/DBKDA2018_v2.0.pdf">13</a>]</span>.
     </li>
     <li class="enumerate" id="x1-5004x2"><b>Real-time analysis of large-scale data: </b>considering stream data analysis is important for most
     existing data mining techniques. But how to do it? Although it&#8217;s a significant challenge in data
     mining, different options are possible. One direction consists of exploring the possibility of updating
     models without their complete re-computation (incremental learning).
     </li>
     <li class="enumerate" id="x1-5006x3"> <b>Large-scale data visualization: </b> many applications such as real-time monitoring of social network
     activities or urban traffic congestion reports involve high information and cognitive load tasks. In this
     context, it is common to have large-scale information visualization interfaces to concurrently display
     system status, alerts, and events. However, displaying all information elements simultaneously would
     result in a saturated and unreadable display. Thus, the development of novel adaptive user interfaces
     (AUIs) are required to help focus the user&#8217;s attention by filtering information relevant to their current
     task. How to optimally set the parameters of filters is a problem that I intend to formalize as a
     Mixed-integer Linear Programming for which we have optimal solvers.</li></ol>
<!--l. 232--><p class="noindent" >Overall, my vision for the future is simple: social media is connecting everything, Web services are becoming more
interactive and personalized, and every embedded system that impacts our lives &#8212; from our daily commute to our
consumer needs &#8212; will become increasingly adaptive. This means that we will have to transform immense
quantities of data into valuable knowledge that should be used for decision-making. This is what I aim to do in my
research.

    
           
            <div style="text-align:center;">
                <hr>
                <!--div class="footer"-->
                © Deakin University 2023.
            </div>
        </div>
        <!-- /container -->

        <!-- Le javascript
    ================================================== -->
        <!-- Placed at the end of the document so the pages load faster -->
    </div>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
    <script src="dist/js/bootstrap.min.js"></script>
</body>

</html>
